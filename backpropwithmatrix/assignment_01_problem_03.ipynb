{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 align=\"right\">by <a href=\"http://cse.iitkgp.ac.in/~adas/\">Abir Das</a> with help of <br> Ram Rakesh and Ankit Singh<br> </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the following details here\n",
    "** Name: ** `SK Mainul Islam`<br/>\n",
    "** Roll Number: ** `18CS72P07`<br/>\n",
    "** Department: ** `Computer Science & Engineering`<br/>\n",
    "** Email: ** `mainulislam79@gmail.com`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble\n",
    "\n",
    "To run and solve this assignment, one must have a working IPython Notebook installation. The easiest way to set it up for both Windows and Linux is to install [Anaconda](https://www.continuum.io/downloads). Then save this file ([`assignment_01.ipynb`]()) to your computer, run Anaconda and choose this file in Anaconda's file explorer. Use `Python 3` version. Below statements assume that you have already followed these instructions. If you are new to Python or its scientific library, Numpy, there are some nice tutorials [here](https://www.learnpython.org/) and [here](http://www.scipy-lectures.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem: You will implement a fully connected neural network from scratch in this problem\n",
    "We marked places where you are expected to add/change your own code with **`##### write your code below #####`** comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "597wDiAvGvuB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are not supposed to import any other python library to work on this assignments.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "'''You are not supposed to import any other python library to work on this assignments.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "B54oZmm1DNWe",
    "outputId": "8c59bd48-230d-4fb9-eba1-82471de363df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 60000\n"
     ]
    }
   ],
   "source": [
    "'''data is loaded from data directory.\n",
    "please don't remove the folder '''\n",
    "\n",
    "x_train = np.load('./data/X_train.npy')\n",
    "x_train = x_train.flatten().reshape(-1,28*28)\n",
    "x_train = x_train / 255.0\n",
    "gt_indices = np.load('./data/y_train.npy')\n",
    "train_length = len(x_train)\n",
    "print(\"Number of training examples: {:d}\".format(train_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LvVFhXNB5xrD"
   },
   "outputs": [],
   "source": [
    "'''Dimensions to be used for creating your model'''\n",
    "\n",
    "batch_size = 64  # batch size\n",
    "input_dim = 784  # input dimension\n",
    "hidden_1_dim = 512  # hidden layer 1 dimension\n",
    "hidden_2_dim = 256  # hidden layer 2 dimension\n",
    "output_dim = 10   # output dimension\n",
    "\n",
    "'''Other hyperparameters'''\n",
    "learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hImaaujc5zXg"
   },
   "outputs": [],
   "source": [
    "#creating one hot vector representation of output classification\n",
    "y_train = np.zeros((train_length, output_dim))\n",
    "# print(y.shape, gt_indices.shape)\n",
    "for i in range(train_length):\n",
    "    y_train[i,gt_indices[i]] = 1\n",
    "    \n",
    "# Number of mini-batches (as integer) in one epoch\n",
    "num_minibatches = np.floor(train_length/batch_size).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W7lHWEWVaVlK",
    "outputId": "4ecb1bfc-4568-44cb-e109-57677da50eb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of mini-batches 937 and total training data used in training:59968.\n"
     ]
    }
   ],
   "source": [
    "print(\"No of mini-batches {:d} and total training data used in training:\\\n",
    "{}.\".format(num_minibatches, num_minibatches*batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C9HRf0Wj52cK"
   },
   "outputs": [],
   "source": [
    "'''Randomly Initialize Weights  from standard normal distribution (i.e., mean = 0 and s.d. = 1.0).\n",
    "Use the dimesnions specified in the cell 3 to initialize your weights matrices. \n",
    "Use the nomenclature W1,W2 etc. (provided below) for the different weight matrices.'''\n",
    "\n",
    "########################## write your code below ##############################################\n",
    "W1 = np.random.normal(0, 1.0, (input_dim, hidden_1_dim))\n",
    "W2 = np.random.normal(0, 1.0, (hidden_1_dim, hidden_2_dim))\n",
    "W3 = np.random.normal(0, 1.0, (hidden_2_dim, output_dim))\n",
    "###############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PmZRrEVb6CJy"
   },
   "outputs": [],
   "source": [
    "# Write a function which computes the softmax where X is vector of scores computed during forward pass\n",
    "def softmax(x):\n",
    "    ##############################write your code here #################################\n",
    "    max_scores=np.max(x,axis=1)\n",
    "    x=x-max_scores[:,np.newaxis]\n",
    "    exp_x=np.exp(x)\n",
    "    sum_exp_x=exp_x.sum(axis=1)\n",
    "    softmax_x=exp_x/sum_exp_x[:,np.newaxis]\n",
    "    return softmax_x\n",
    "    ####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "Gjz4yhwE6JQw",
    "outputId": "341578db-29a4-48ca-b0f8-a0343aadd24b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0, iteration: 0, Loss: 16.5458 \n",
      " Epoch: 1, iteration: 937, Loss: 13.8155 \n",
      " Epoch: 2, iteration: 1874, Loss: 11.5129 \n",
      " Epoch: 3, iteration: 2811, Loss: 10.5064 \n",
      " Epoch: 4, iteration: 3748, Loss: 9.4982 \n",
      " Epoch: 5, iteration: 4685, Loss: 8.6347 \n",
      " Epoch: 6, iteration: 5622, Loss: 8.3437 \n",
      " Epoch: 7, iteration: 6559, Loss: 7.1956 \n",
      " Epoch: 8, iteration: 7496, Loss: 6.8722 \n",
      " Epoch: 9, iteration: 8433, Loss: 5.1808 \n",
      " Epoch: 10, iteration: 9370, Loss: 5.1808 \n",
      " Epoch: 11, iteration: 10307, Loss: 5.1808 \n",
      " Epoch: 12, iteration: 11244, Loss: 5.1808 \n",
      " Epoch: 13, iteration: 12181, Loss: 5.1808 \n",
      " Epoch: 14, iteration: 13118, Loss: 5.1808 \n",
      " Epoch: 15, iteration: 14055, Loss: 5.1808 \n",
      " Epoch: 16, iteration: 14992, Loss: 5.1808 \n",
      " Epoch: 17, iteration: 15929, Loss: 5.1808 \n",
      " Epoch: 18, iteration: 16866, Loss: 5.1808 \n",
      " Epoch: 19, iteration: 17803, Loss: 5.1808 \n",
      " Epoch: 20, iteration: 18740, Loss: 5.1808 \n",
      " Epoch: 21, iteration: 19677, Loss: 5.1808 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "no_of_iterations = 20000\n",
    "loss_list=[]\n",
    "i_epoch = 0\n",
    "for i_iter in range(no_of_iterations):\n",
    "    batch_elem_idx = i_iter%num_minibatches\n",
    "    x_batchinput = x_train[batch_elem_idx*batch_size:(batch_elem_idx+1)*batch_size]\n",
    "    \n",
    "    ########################## write your code below ##############################################\n",
    "    ######################### Forward Pass Block #####################################\n",
    "    '''Write the code for forward block of the neural network with 2 hidden layers.\n",
    "    Please stick to the notation below which follows the notation provided in the lecture slides.\n",
    "    Note that you are allowed to write the right hand sides of these variables in more than\n",
    "    one line if that is convenient for you.'''\n",
    "    \n",
    "    # first hidden layer implementation\n",
    "    a1 = x_batchinput.dot(W1)\n",
    "    #print(a1)\n",
    "    # implement Relu layer\n",
    "    h1 = np.maximum(a1,0)\n",
    "    #  implement 2 hidden layer\n",
    "    a2 = h1.dot(W2)\n",
    "    #print(a2)\n",
    "    # implement Relu activation \n",
    "    h2 = np.maximum(a2,0)\n",
    "    #implement linear output layer\n",
    "    a3 = h2.dot(W3)\n",
    "    #print(a3)\n",
    "    # softmax layer\n",
    "    softmax_score = softmax(a3)\n",
    "    #print(softmax_score)#enusre you have implemented the softmax function defined above\n",
    "    ##################################################################################\n",
    "    ###############################################################################################\n",
    "\n",
    "    neg_log_softmax_score = -np.log(softmax_score+0.00000001) # The small number is added to avoid 0 input to log function\n",
    "    # Compute and print loss\n",
    "    if i_iter%num_minibatches == 0:\n",
    "        loss = np.mean(np.diag(np.take(neg_log_softmax_score, gt_indices[batch_elem_idx*batch_size:(batch_elem_idx+1)*batch_size],\\\n",
    "                                       axis=1)))\n",
    "        print(\" Epoch: {:d}, iteration: {:d}, Loss: {:6.4f} \".format(i_epoch, i_iter, loss))\n",
    "        loss_list.append(loss)\n",
    "        i_epoch += 1\n",
    "        # Each 10th epoch reduce learning rate by a factor of 10\n",
    "        if i_epoch%10 == 0:\n",
    "            learning_rate /= 10.0\n",
    "    ################################### Backpropagation Code Block #####################################\n",
    "    ''' Use the convention grad_{} for computing the gradients.\n",
    "    for e.g \n",
    "        grad_W1 for gradients w.r.t. weight W1\n",
    "        grad_w2 for gradients w.r.t. weights W2'''\n",
    "    ########################## write your code below ##############################################\n",
    "    # Gradient of cross-entropy loss w.r.t. preactivation of the output layer\n",
    "    grad_softmax_score = softmax_score-y_train[batch_elem_idx*batch_size:(batch_elem_idx+1)*batch_size] \n",
    "    # gradient w.r.t W3\n",
    "    grad_W3 = 1/batch_size*(h2.T).dot(grad_softmax_score)\n",
    "    # gradient w.r.t h2\n",
    "    grad_h2 = 1*(h2>=0)\n",
    "    # gradient w.r.t a2\n",
    "    grad_a2 = np.multiply(grad_softmax_score.dot(W3.T) ,grad_h2)\n",
    "    # gradient w.r.t W2\n",
    "    grad_W2 = 1/batch_size*(h1.T).dot(grad_a2)\n",
    "    # gradient w.r.t h1\n",
    "    grad_h1 = 1*(h1>=0)\n",
    "    # gradient w.r.t a1\n",
    "    grad_a1 = np.multiply(grad_a2.dot(W2.T) ,grad_h1)\n",
    "    # gradient w.r.t W1\n",
    "    grad_W1 = 1/batch_size*np.dot(x_batchinput.T, grad_a1)\n",
    "    ###############################################################################################\n",
    "    ####################################################################################################\n",
    "    \n",
    "    \n",
    "    ################################ Update Weights Block using SGD ####################################\n",
    "    W3 -= learning_rate * grad_W3\n",
    "    W2 -= learning_rate * grad_W2\n",
    "    W1 -= learning_rate * grad_W1\n",
    "    ####################################################################################################\n",
    "    \n",
    "#plotting the loss\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(loss_list)\n",
    "plt.title('Loss vs epochs')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading the test data from data/X_test.npy and data/y_test.npy.'''\n",
    "x_test = np.load('./data/X_test.npy')\n",
    "x_test = x_test.flatten().reshape(-1,28*28)\n",
    "x_test = x_test / 255.0\n",
    "y_test = np.load('./data/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 70.29 %\n"
     ]
    }
   ],
   "source": [
    "batch_size_test = 100 # Deliberately taken 100 so that it divides the test data size\n",
    "num_minibatches = len(y_test)/batch_size_test\n",
    "test_correct = 0\n",
    "\n",
    "'''Only forward block code and compute softmax_score .'''\n",
    "for i_iter in range(int(num_minibatches)):\n",
    "    \n",
    "    '''Get one minibatch'''\n",
    "    batch_elem_idx = i_iter%num_minibatches\n",
    "    x_batchinput = x_test[i_iter*batch_size_test:(i_iter+1)*batch_size_test]\n",
    "    \n",
    "    ######### copy only the forward pass block of your code and pass the x_batchinput to it and compute softmax_score ##########\n",
    "    # first hidden layer implementation\n",
    "    a1 = x_batchinput.dot(W1)\n",
    "    # implement Relu layer\n",
    "    h1 = np.maximum(a1,0)\n",
    "    #  implement 2nd hidden layer\n",
    "    a2 = h1.dot(W2)\n",
    "    # implement Relu activation \n",
    "    h2 = np.maximum(a2,0)\n",
    "    #implement linear output layer\n",
    "    a3 = h2.dot(W3)\n",
    "    # softmax layer\n",
    "    softmax_score = softmax(a3) #enusre you have implemented the softmax function defined above\n",
    "    ##################################################################################\n",
    "    \n",
    "    y_batchinput = y_test[i_iter*batch_size_test:(i_iter+1)*batch_size_test]\n",
    "    \n",
    "    y_pred = np.argmax(softmax_score, axis=1)\n",
    "    num_correct_i_iter = np.sum(y_pred == y_batchinput)\n",
    "    test_correct += num_correct_i_iter\n",
    "print (\"Test accuracy is {:4.2f} %\".format(test_correct/len(y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2_Hidden_MLP_New.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
